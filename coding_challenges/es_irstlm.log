dict:
loaded 
Splitting dictionary into 3 lists
Dictionary 0: (thr: 5084.66666666667 , 15254, 0 , 3)
Dictionary 1: (thr: 5067 , 10134 , 5120 , 2)
Dictionary 2: (thr: 5066 , 5066 , 5068 , 1)
Extracting n-gram statistics for each word list
Important: dictionary must be ordered according to order of appearance of words in data
used to generate n-gram blocks,  so that sub language model blocks results ordered too
Extracting n-gram statistics for dict.000
Extracting n-gram statistics for dict.001
[codesize 3]
Extracting n-gram statistics for dict.002
[codesize 3]
[codesize 3]
dict:loaded 
load:prepare initial n-grams to make table consistent
starting to use OOV words [<s>]
raaraadict:aloaded 
load:prepare initial n-grams to make table consistent
starting to use OOV words [<s>]
aaaarrraraaaaaaaaaaaaaaaaaaadding some more n-grams to make table consistent

savetxt in Google format: nGrAm 3 4456 ngram
aadding some more n-grams to make table consistent

savetxt in Google format: nGrAm 3 4814 ngram
dict:loaded 
load:prepare initial n-grams to make table consistent
starting to use OOV words [<s>]
raaaaaaaaaaaaaaaa
aaaaaaaaaa
aaaadding some more n-grams to make table consistent

savetxt in Google format: nGrAm 3 3806 ngram

Estimating language models for each word list
Estimating language models for dict.000
Estimating language models for dict.001
Estimating language models for dict.002
Merging language models into data-es-pt/Europarl.tag-clean.pt.lm.gz
merge-sublm.pl --size 3 --sublm tmp/lm.dict --lm data-es-pt/Europarl.tag-clean.pt.lm.gz --backoff 0
Compute total sizes of n-grams
join files tmp/lm.dict.000.1gr.gz tmp/lm.dict.001.1gr.gz tmp/lm.dict.002.1gr.gz
implicitely add <unk> word to counters
n:1 size:3199 unk:0
join files tmp/lm.dict.000.2gr.gz tmp/lm.dict.001.2gr.gz tmp/lm.dict.002.2gr.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.000.2gr.gz | grep -v '10000.000' | wc -l > wc50375
Executing: /usr/bin/gunzip -c tmp/lm.dict.001.2gr.gz | grep -v '10000.000' | wc -l > wc50375
Executing: /usr/bin/gunzip -c tmp/lm.dict.002.2gr.gz | grep -v '10000.000' | wc -l > wc50375
n:2 size:9285 unk:0
join files tmp/lm.dict.000.3gr.gz tmp/lm.dict.001.3gr.gz tmp/lm.dict.002.3gr.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.000.3gr.gz | grep -v '10000.000' | wc -l > wc50375
Executing: /usr/bin/gunzip -c tmp/lm.dict.001.3gr.gz | grep -v '10000.000' | wc -l > wc50375
Executing: /usr/bin/gunzip -c tmp/lm.dict.002.3gr.gz | grep -v '10000.000' | wc -l > wc50375
n:3 size:13076 unk:0
Merge all sub LMs
Write LM Header
Writing LM Tables
Level 1
input from: tmp/lm.dict.000.1gr.gz tmp/lm.dict.001.1gr.gz tmp/lm.dict.002.1gr.gz
Level 2
input from: tmp/lm.dict.000.2gr.gz tmp/lm.dict.001.2gr.gz tmp/lm.dict.002.2gr.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.000.2gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.001.2gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.002.2gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Level 3
input from: tmp/lm.dict.000.3gr.gz tmp/lm.dict.001.3gr.gz tmp/lm.dict.002.3gr.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.000.3gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.001.3gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Executing: /usr/bin/gunzip -c tmp/lm.dict.002.3gr.gz | grep -v '10000.000' | gzip -c >> data-es-pt/Europarl.tag-clean.pt.lm.gz
Cleaning temporary directory tmp
Removing temporary directory tmp
